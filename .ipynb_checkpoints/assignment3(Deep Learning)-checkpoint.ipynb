{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(54,36;334.8x217.44)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAASF0lEQVR4nO3dbYxUZZYH8P8BeW9Q+gVshQhMMNFoBKyQNb7EzcSJ8AXnw2yGmJFNdBmjkwwJH9a4MeMHNzGbHWbHZDMGlAyzmXUyZCDywUyGIBGJihYGW1gQW8GhoaW7aaBfQBA4+6Gvkxb7ntNTt6rubc7/l5DurlO37tMFf6q7zn2eR1QVRHTtG5f3AIioPhh2oiAYdqIgGHaiIBh2oiCuq+fJmpubdd68efU8ZV1cuXLFrB8/ftysDw4OmvWmpiaz3tLSYtbHqtOnT5v1np4esz5jxozU2uzZsysaU9EdPXoUPT09MlItU9hF5GEAvwYwHsArqvqidf958+ahXC5nOWUheWF97rnnzPo777xj1h977DGz/tRTT5n1sWrz5s1m/ZVXXjHry5YtS62tWbOmojEVXalUSq1V/GO8iIwH8N8AlgG4HcBKEbm90scjotrK8jv7UgDtqvq5ql4E8AcAK6ozLCKqtixhvxnAsWFfdyS3fYuIrBaRsoiUu7u7M5yOiLLIEvaR3gT4zrW3qrpeVUuqWrpW30giGguyhL0DwNxhX88BcCLbcIioVrKE/QMAC0VkvohMBPBjANuqMywiqjbJMutNRJYD+C8Mtd42quq/W/cvlUo6VltvTz75ZGrtrbfeMo/1+vBez/fAgQNm3fr1aO7cuak1AFi4cKFZv/766816b2+vWbfaihcvXjSP7evrM+utra1m3WqJzpkzxzx2w4YNZn3BggVmPS+lUgnlcrn6fXZVfQPAG1keg4jqg5fLEgXBsBMFwbATBcGwEwXBsBMFwbATBVHX+exF9uabb5r1I0eOpNYWL15sHuv1i70+/F133WXWrTkHn332mXmsNz3XmjIJAG1tbWb9uuvS/4k1Nzebx3rPa1dXl1mfP39+au3MmTPmsWvXrjXrW7duNetFxFd2oiAYdqIgGHaiIBh2oiAYdqIgGHaiINh6S2zfvt2sW0tgX7hwwTx2woQJZv3rr782616LympveVOYL1++bNa96bVTpkwx6w0NDam16dOnm8d6S3BPnTrVrFvfuzfF1WuX7t6926zfd999Zj0PfGUnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCoJ99sSJE/b+Ftb2v1n77F6v23v8iRMnptasPjfgL+fsGT9+vFm3+tXnzp0zj/X66N73Nm5c+muZ95yLjLga89+wz05EhcWwEwXBsBMFwbATBcGwEwXBsBMFwbATBRGmz+4t1+zNX7a2Lva2Nf7qq6/Museb7271jAcGBsxjL126ZNatHj7gj8163r1ze39n3rknT55s1i1en/3w4cMVP3ZeMoVdRI4C6AdwGcAlVbUXGSei3FTjlf0fVbWnCo9DRDXE39mJgsgadgXwFxHZKyKrR7qDiKwWkbKIlK1tioiotrKG/V5VXQJgGYCnReSBq++gqutVtaSqpZaWloynI6JKZQq7qp5IPnYB2ApgaTUGRUTVV3HYRWSaiEz/5nMAPwCwv1oDI6LqyvJu/GwAW5N+5HUA/ldV/1yVUdWAteUy4Pd0z58/n1qz5roDwMyZM8261y/u7+8369a68d58dW9dee8aAe94ay6/12f3HtvrhVvz2b258h5vTfsiqjjsqvo5AHvjcCIqDLbeiIJg2ImCYNiJgmDYiYJg2ImCCDPFtbOz06xPmjTJrFttHK9FdMstt5h1b1ljb2tj6/zeFFdvmWvr+x7N8VZb0dvu2Vum2pt+29ramlobHBw0j/Wet6amJrPuXRqex9WkfGUnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCiJMn/3UqVNm3erJAsDZs2dTa7t27TKPffTRR836TTfdZNa9awSsLZ29XrbXq/ZY02u9x/emuHqPPWvWLLP+3nvvpda86wduu+02s+4tPX7o0CGzzj47EdUMw04UBMNOFATDThQEw04UBMNOFATDThREmD67N7/YW655586dFT/23r17zfoDD3xnI51vaWtrM+s33HBDas3ro3tLaHvz1b2lqq1eurdMtTfn3FsnwFoues+ePeax3tjmzJlj1j/66COzfv/995v1WuArO1EQDDtREAw7URAMO1EQDDtREAw7URAMO1EQYfrsTzzxhFl/6KGHzPqZM2dSay+99JJ57MaNG826N/d58uTJZt3qpXt9cG9et7edtLdmvjU2b9tk79qH999/36xv3rw5tbZu3TrzWG9L5pdfftmse/sQ5MF9ZReRjSLSJSL7h93WKCLbReTT5KO9ATkR5W40P8b/FsDDV932DIAdqroQwI7kayIqMDfsqroLQO9VN68AsCn5fBOAR6o8LiKqskrfoJutqp0AkHxMXQxMRFaLSFlEyt415ERUOzV/N15V16tqSVVLeSyyR0RDKg37SRFpBYDkY1f1hkREtVBp2LcBWJV8vgrA69UZDhHVittnF5HXADwIoFlEOgD8AsCLAP4oIo8D+CuAH9VykPXgzY3esmVLxY99xx13mPW3337brHtzp71edxbefHevbu09P2PGDPNYb61/b1/7xsbG1NoLL7xgHnstcsOuqitTSt+v8liIqIZ4uSxREAw7URAMO1EQDDtREAw7URBhprh67aksLSZvueU777zTrDc0NJh1ETHr1tiybovsTYH1WOf3vi9vCuyxY8cqGtNoeG09z/jx46s0kurhKztREAw7URAMO1EQDDtREAw7URAMO1EQDDtREGH67F5P1+uLZuk3e310j7ftsrW9sNdH9/rJWXr8gP28edsiT5s2zax7z0sW3t+397wUEV/ZiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYII02fPyupHe71sb9tj73hvvvzAwEBqbcqUKeaxXq/bO7fXZ7e+t/Pnz5vHen30W2+91axn4a1/wD47ERUWw04UBMNOFATDThQEw04UBMNOFATDThQE++x1cPz4cbPu9bK9XrhlcHAw07k93rxv6xoD7/qCLHPlAaCjoyO1luc22HlxX9lFZKOIdInI/mG3PS8ix0VkX/JneW2HSURZjebH+N8CeHiE23+lqouSP29Ud1hEVG1u2FV1F4DeOoyFiGooyxt0PxORtuTH/JlpdxKR1SJSFpFyd3d3htMRURaVhv03AL4HYBGATgC/TLujqq5X1ZKqllpaWio8HRFlVVHYVfWkql5W1SsANgBYWt1hEVG1VRR2EWkd9uUPAexPuy8RFYPbZxeR1wA8CKBZRDoA/ALAgyKyCIACOArgpzUcYyFkmb/87rvvmnWv133x4kWzbvWjJ02aZB7rzSn3jvfW27ce31sX3ttb3ht7V1dXas3rs3s9/iLuv+5xw66qK0e4+dUajIWIaoiXyxIFwbATBcGwEwXBsBMFwbATBcEprqOUZcvm9vZ2s56lfQXYrTmvdZZ1messLShv6u7UqVPNujf2Tz75JLW2ZMkS89ixuFS0h6/sREEw7ERBMOxEQTDsREEw7ERBMOxEQTDsREGwz57IsmyxNxXTW47L64V7Pd8syx5702e9sXl9eGtsXo/e+zvxpgZbfXZPlusqiura+46IaEQMO1EQDDtREAw7URAMO1EQDDtREAw7URDssyey9Kr7+vrMelNTk1m3ljwGgBkzZpj1/v7+1JrXi758+bJZ93jXGFjPq3du7/oC79zeOgIWr8/u/Xsp4nx4vrITBcGwEwXBsBMFwbATBcGwEwXBsBMFwbATBcE+eyJLn/3YsWNm3evDez3ZCxcumHVrTrr32N7a697a7pMnTzbr1vm99fCnT59u1r259BMnTkyted+3d33CWNzS2X1lF5G5IrJTRA6KyAER+Xlye6OIbBeRT5OPM2s/XCKq1Gh+jL8EYK2q3gbgHwA8LSK3A3gGwA5VXQhgR/I1ERWUG3ZV7VTVD5PP+wEcBHAzgBUANiV32wTgkVoNkoiy+7veoBOReQAWA9gDYLaqdgJD/yEAmJVyzGoRKYtI2VuLjYhqZ9RhF5EGAH8CsEZV7XechlHV9apaUtVSS0tLJWMkoioYVdhFZAKGgv57Vd2S3HxSRFqTeisAe+oWEeXKbb3JUO/kVQAHVXXdsNI2AKsAvJh8fL0mIxwDDh06ZNa91ltjY6NZP336tFnP0mLypolmbb1ZYztz5ox5rNf+8s5tjf3s2bPmsc3NzWY9S6s2L6Pps98L4CcAPhaRfcltz2Io5H8UkccB/BXAj2ozRCKqBjfsqrobQNqVEd+v7nCIqFZ4uSxREAw7URAMO1EQDDtREAw7URCc4loFvb29Zt2boupN1fR6wtZS1VmXa/amcnp9+oaGhtSa12f3prh6Y7O+9y+//NI81uuzj0V8ZScKgmEnCoJhJwqCYScKgmEnCoJhJwqCYScKgn32RJb5yUeOHDHr3rxsz8DAgFlfsGBBas3r8Xu8Hv/MmfaiwtZ8du/78paanjRpklm3+vDWNtejMRbns/OVnSgIhp0oCIadKAiGnSgIhp0oCIadKAiGnSgI9tmrwNue11vfPGs/2erjW9s5A8Dg4KBZ9+bqz58/36x757d4c/G9591aM9+bx+/x5tIXEV/ZiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYIYzf7scwH8DsCNAK4AWK+qvxaR5wH8C4Du5K7PquobtRpokVlztgG/H+z1omfNmmXWx41L/z/b69F75/bG7u0tf+7cudTatGnTzGO9OeNZeuXetQ8e6zkvqtFcVHMJwFpV/VBEpgPYKyLbk9qvVPU/azc8IqqW0ezP3gmgM/m8X0QOAri51gMjour6u34WEZF5ABYD2JPc9DMRaRORjSIy4vpEIrJaRMoiUu7u7h7pLkRUB6MOu4g0APgTgDWq2gfgNwC+B2ARhl75fznScaq6XlVLqlpqaWmpwpCJqBKjCruITMBQ0H+vqlsAQFVPquplVb0CYAOApbUbJhFl5YZdht7yfBXAQVVdN+z21mF3+yGA/dUfHhFVy2jejb8XwE8AfCwi+5LbngWwUkQWAVAARwH8tCYjHAMOHz5s1r2tib2lpk+fPl1x3WutnTp1yqz39fWZ9fb2drN+8uTJ1Nq+fftSawBwzz33mHVvKWqrdee1S69Fo3k3fjeAkRqaIXvqRGPV2LsygIgqwrATBcGwEwXBsBMFwbATBcGwEwXBpaQTWaYslkols97T02PWvSms3jRV6zJkb4rqiRMnMtXvvvtus25tGf3FF1+Yx3pTWKdOnWrWrT7+jTfeaB7rGYtTXMfeiImoIgw7URAMO1EQDDtREAw7URAMO1EQDDtREOIt11vVk4l0AxjeXG0GYDeh81PUsRV1XADHVqlqju0WVR3xwou6hv07Jxcpq6p9RUpOijq2oo4L4NgqVa+x8cd4oiAYdqIg8g77+pzPbynq2Io6LoBjq1Rdxpbr7+xEVD95v7ITUZ0w7ERB5BJ2EXlYRD4RkXYReSaPMaQRkaMi8rGI7BORcs5j2SgiXSKyf9htjSKyXUQ+TT6OuMdeTmN7XkSOJ8/dPhFZntPY5orIThE5KCIHROTnye25PnfGuOryvNX9d3YRGQ/gMICHAHQA+ADASlX9v7oOJIWIHAVQUtXcL8AQkQcADAD4narekdz2HwB6VfXF5D/Kmar6rwUZ2/MABvLexjvZrah1+DbjAB4B8M/I8bkzxvVPqMPzlscr+1IA7ar6uapeBPAHACtyGEfhqeouAL1X3bwCwKbk800Y+sdSdyljKwRV7VTVD5PP+wF8s814rs+dMa66yCPsNwM4NuzrDhRrv3cF8BcR2Ssiq/MezAhmq2onMPSPB4C9plX9udt419NV24wX5rmrZPvzrPII+0gLixWp/3evqi4BsAzA08mPqzQ6o9rGu15G2Ga8ECrd/jyrPMLeAWDusK/nALBXNawjVT2RfOwCsBXF24r65Dc76CYfu3Iez98UaRvvkbYZRwGeuzy3P88j7B8AWCgi80VkIoAfA9iWwzi+Q0SmJW+cQESmAfgBircV9TYAq5LPVwF4PcexfEtRtvFO22YcOT93uW9/rqp1/wNgOYbekf8MwL/lMYaUcS0A8FHy50DeYwPwGoZ+rPsaQz8RPQ6gCcAOAJ8mHxsLNLb/AfAxgDYMBas1p7Hdh6FfDdsA7Ev+LM/7uTPGVZfnjZfLEgXBK+iIgmDYiYJg2ImCYNiJgmDYiYJg2ImCYNiJgvh/ig5J2w5kHbgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "fileObjectx = open('trainX.pickle','rb')\n",
    "fileObjecty = open('trainY.pickle','rb')\n",
    "fileObjectX = open('testX.pickle','rb')\n",
    "# load the object from the file into var b\n",
    "trainX= pickle.load(fileObjectx)  \n",
    "print(plt.imshow(trainX[10],cmap=plt.cm.binary))\n",
    "plt.show()\n",
    "trainX.shape\n",
    "trainY= pickle.load(fileObjecty)\n",
    "trainY.shape\n",
    "testX1= pickle.load(fileObjectX)\n",
    "\n",
    "testX1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(trainX,trainY,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 28, 28)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for training the model\n",
    "\n",
    "#number of training examples utilized in one iteration\n",
    "batch_size = 128\n",
    "\n",
    "#number of classes of the output\n",
    "num_classes = 10\n",
    "\n",
    "#number to times the model loop through data for training\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (45000, 28, 28)\n",
      "45000 train samples\n",
      "15000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (45000, 784))\n",
    "X_test = np.reshape(X_test, (15000, 784))\n",
    "\n",
    "#data for which prediction is to be made\n",
    "testX=np.reshape(testX1,(10000,784))\n",
    "\n",
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0622 15:29:41.199619 10972 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0622 15:29:41.216573 10972 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0622 15:29:41.219563 10972 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0622 15:29:41.239514 10972 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0622 15:29:41.248489 10972 deprecation.py:506] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0622 15:29:41.353206 10972 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0622 15:29:41.425218 10972 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 545,810\n",
      "Trainable params: 545,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=784), )\n",
    "model.add(Activation('relu'))\n",
    "#Using Dropout to stop overfitting\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "#Adadelta continues learning even when many updates have been done\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0622 15:29:45.557660 10972 deprecation.py:323] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 16s 347us/step - loss: 0.6805 - acc: 0.7573 - val_loss: 0.4853 - val_acc: 0.8063\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 12s 277us/step - loss: 0.4724 - acc: 0.8280 - val_loss: 0.4274 - val_acc: 0.8344\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 13s 280us/step - loss: 0.4273 - acc: 0.8431 - val_loss: 0.3730 - val_acc: 0.8678\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 13s 293us/step - loss: 0.3972 - acc: 0.8534 - val_loss: 0.3799 - val_acc: 0.8627\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 13s 287us/step - loss: 0.3785 - acc: 0.8602 - val_loss: 0.3638 - val_acc: 0.8661\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 13s 290us/step - loss: 0.3614 - acc: 0.8674 - val_loss: 0.3645 - val_acc: 0.8676\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 13s 286us/step - loss: 0.3535 - acc: 0.8699 - val_loss: 0.3491 - val_acc: 0.8691\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 20s 442us/step - loss: 0.3409 - acc: 0.8760 - val_loss: 0.3563 - val_acc: 0.8719\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 15s 322us/step - loss: 0.3338 - acc: 0.8770 - val_loss: 0.3252 - val_acc: 0.8817\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 17s 380us/step - loss: 0.3231 - acc: 0.8807 - val_loss: 0.3393 - val_acc: 0.8755\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 19s 413us/step - loss: 0.3197 - acc: 0.8836 - val_loss: 0.3160 - val_acc: 0.8850\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 13s 289us/step - loss: 0.3152 - acc: 0.8843 - val_loss: 0.3277 - val_acc: 0.8816\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 13s 284us/step - loss: 0.3080 - acc: 0.8860 - val_loss: 0.3118 - val_acc: 0.8877\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 12s 258us/step - loss: 0.2976 - acc: 0.8892 - val_loss: 0.3295 - val_acc: 0.8809\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 9s 199us/step - loss: 0.2961 - acc: 0.8908 - val_loss: 0.3448 - val_acc: 0.8707\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 9s 210us/step - loss: 0.2922 - acc: 0.8912 - val_loss: 0.3111 - val_acc: 0.8899\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 9s 196us/step - loss: 0.2886 - acc: 0.8932 - val_loss: 0.3094 - val_acc: 0.8899\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 9s 199us/step - loss: 0.2792 - acc: 0.8974 - val_loss: 0.3311 - val_acc: 0.8859\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 9s 207us/step - loss: 0.2786 - acc: 0.8966 - val_loss: 0.3046 - val_acc: 0.8919\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 9s 202us/step - loss: 0.2736 - acc: 0.8983 - val_loss: 0.3128 - val_acc: 0.8898\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 9s 193us/step - loss: 0.2688 - acc: 0.9004 - val_loss: 0.3091 - val_acc: 0.8931\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 9s 194us/step - loss: 0.2660 - acc: 0.9012 - val_loss: 0.3164 - val_acc: 0.8864\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 9s 203us/step - loss: 0.2625 - acc: 0.9014 - val_loss: 0.3045 - val_acc: 0.8937\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 9s 196us/step - loss: 0.2606 - acc: 0.9013 - val_loss: 0.3103 - val_acc: 0.8929\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 10s 218us/step - loss: 0.2556 - acc: 0.9050 - val_loss: 0.3123 - val_acc: 0.8911\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 9s 205us/step - loss: 0.2507 - acc: 0.9066 - val_loss: 0.3185 - val_acc: 0.8909\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 9s 195us/step - loss: 0.2515 - acc: 0.9063 - val_loss: 0.3056 - val_acc: 0.8932\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 9s 198us/step - loss: 0.2449 - acc: 0.9091 - val_loss: 0.3029 - val_acc: 0.8948\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 10s 218us/step - loss: 0.2439 - acc: 0.9083 - val_loss: 0.3105 - val_acc: 0.8967\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 10s 211us/step - loss: 0.2412 - acc: 0.9098 - val_loss: 0.3261 - val_acc: 0.8913\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 9s 197us/step - loss: 0.2376 - acc: 0.9117 - val_loss: 0.3100 - val_acc: 0.8951\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 9s 202us/step - loss: 0.2327 - acc: 0.9128 - val_loss: 0.3384 - val_acc: 0.8872\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 9s 196us/step - loss: 0.2323 - acc: 0.9126 - val_loss: 0.3030 - val_acc: 0.8972\n",
      "Test loss: 0.30302793782552084\n",
      "Test accuracy: 0.8971999999682109\n"
     ]
    }
   ],
   "source": [
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "\n",
    "#Train model\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),callbacks=[early_stopping_monitor])\n",
    "\n",
    "#loss and accuracy returnedfrom evaluate function\n",
    "loss,accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Saving the model \n",
    "model.save('apparels_image_reader.model')\n",
    "new_model=keras.models.load_model('apparels_image_reader.model')\n",
    "prediction=new_model.predict(testX)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the predictions in a pickle file named result.\n",
    "filename = 'result.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(prediction,outfile)\n",
    "outfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

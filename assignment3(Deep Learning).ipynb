{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(80,52.8;496x369.6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deep learning model for identifying images\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "#Opening files for reading the data\n",
    "fileObjectx = open('trainX.pickle','rb')\n",
    "fileObjecty = open('trainY.pickle','rb')\n",
    "fileObjectX = open('testX.pickle','rb')\n",
    "\n",
    "# load the object from the files\n",
    "trainX= pickle.load(fileObjectx)  \n",
    "print(plt.imshow(trainX[10],cmap=plt.cm.binary))\n",
    "plt.show()\n",
    "trainX.shape\n",
    "trainY= pickle.load(fileObjecty)\n",
    "trainY.shape\n",
    "testX_retrive= pickle.load(fileObjectX)\n",
    "\n",
    "testX_retrive.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training data and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(trainX,trainY,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 28, 28)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for training the model\n",
    "\n",
    "#number of training examples utilized in one iteration\n",
    "batch_size = 128\n",
    "\n",
    "#number of classes of the output\n",
    "num_classes = 10\n",
    "\n",
    "#number of times the model loop through data for training\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (45000, 28, 28)\n",
      "45000 train samples\n",
      "15000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (45000, 784))\n",
    "X_test = np.reshape(X_test, (15000, 784))\n",
    "\n",
    "#data for which prediction is to be made\n",
    "testX=np.reshape(testX_retrive,(10000,784))\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 01:00:45.202117 12192 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0623 01:00:45.224059 12192 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0623 01:00:45.227053 12192 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0623 01:00:45.246341 12192 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0623 01:00:45.258997 12192 deprecation.py:506] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0623 01:00:45.387674 12192 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0623 01:00:45.402629 12192 deprecation_wrapper.py:119] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 545,810\n",
      "Trainable params: 545,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Using Sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=784), )\n",
    "# Activation function-Rectified Linear Unit,returns 0 if it founds a negative value and the value x for positive value \n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Using Dropout to stop overfitting\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Using Dropout to stop overfitting\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "#Adadelta optimizer continues learning even when many updates have been done\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 01:00:57.296142 12192 deprecation.py:323] From E:\\anaconda\\envs\\assignment3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 11s 234us/step - loss: 0.6778 - acc: 0.7560 - val_loss: 0.4487 - val_acc: 0.8333\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 10s 230us/step - loss: 0.4731 - acc: 0.8283 - val_loss: 0.4189 - val_acc: 0.8377\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 10s 231us/step - loss: 0.4296 - acc: 0.8429 - val_loss: 0.4086 - val_acc: 0.8449\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 10s 226us/step - loss: 0.3980 - acc: 0.8538 - val_loss: 0.3692 - val_acc: 0.8649\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 10s 228us/step - loss: 0.3787 - acc: 0.8609 - val_loss: 0.3682 - val_acc: 0.8673\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 10s 231us/step - loss: 0.3644 - acc: 0.8668 - val_loss: 0.3401 - val_acc: 0.8739\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 10s 229us/step - loss: 0.3541 - acc: 0.8700 - val_loss: 0.3287 - val_acc: 0.8815\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 10s 231us/step - loss: 0.3412 - acc: 0.8739 - val_loss: 0.3663 - val_acc: 0.8683\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 10s 232us/step - loss: 0.3337 - acc: 0.8777 - val_loss: 0.3335 - val_acc: 0.8741\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 10s 229us/step - loss: 0.3287 - acc: 0.8776 - val_loss: 0.3306 - val_acc: 0.8780\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 10s 229us/step - loss: 0.3176 - acc: 0.8822 - val_loss: 0.3470 - val_acc: 0.8757\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 10s 225us/step - loss: 0.3114 - acc: 0.8845 - val_loss: 0.3213 - val_acc: 0.8833\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 10s 226us/step - loss: 0.3044 - acc: 0.8864 - val_loss: 0.3406 - val_acc: 0.8779\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 10s 225us/step - loss: 0.3011 - acc: 0.8875 - val_loss: 0.3478 - val_acc: 0.8779\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 10s 222us/step - loss: 0.2935 - acc: 0.8912 - val_loss: 0.3604 - val_acc: 0.8744\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 10s 225us/step - loss: 0.2893 - acc: 0.8930 - val_loss: 0.3172 - val_acc: 0.8879\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 10s 227us/step - loss: 0.2837 - acc: 0.8945 - val_loss: 0.3197 - val_acc: 0.8861\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 10s 222us/step - loss: 0.2806 - acc: 0.8960 - val_loss: 0.3063 - val_acc: 0.8905\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 10s 227us/step - loss: 0.2756 - acc: 0.8979 - val_loss: 0.3247 - val_acc: 0.8847\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 10s 221us/step - loss: 0.2728 - acc: 0.8982 - val_loss: 0.3139 - val_acc: 0.8902\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 10s 224us/step - loss: 0.2666 - acc: 0.9021 - val_loss: 0.3043 - val_acc: 0.8925\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 10s 226us/step - loss: 0.2652 - acc: 0.9013 - val_loss: 0.3086 - val_acc: 0.8895\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 10s 220us/step - loss: 0.2617 - acc: 0.9038 - val_loss: 0.3104 - val_acc: 0.8933\n",
      "Epoch 24/100\n",
      "25728/45000 [================>.............] - ETA: 4s - loss: 0.2599 - acc: 0.9045"
     ]
    }
   ],
   "source": [
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "\n",
    "#Train model\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),callbacks=[early_stopping_monitor])\n",
    "\n",
    "#loss and accuracy returnedfrom evaluate function\n",
    "loss,accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Predicting for the test data\n",
    "pred=model.predict(X_test)\n",
    "test_result=np.argmax(pred[0])\n",
    "print(test_result)\n",
    "\n",
    "#Saving the model \n",
    "model.save('apparels_image_reader.model')\n",
    "\n",
    "#loading the saved model for prediction \n",
    "new_model=keras.models.load_model('apparels_image_reader.model')\n",
    "\n",
    "#Prediction on the new data\n",
    "prediction=new_model.predict(testX)\n",
    "#print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the predictions in a pickle file named result.\n",
    "filename = 'result.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(prediction,outfile)\n",
    "outfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
